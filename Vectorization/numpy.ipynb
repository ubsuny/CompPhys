{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization\n",
    "\n",
    "This shows the advantage of using numpy built in vectorization (and other optimizations) on the example of calculating the dot product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "833323333350000.0\n"
     ]
    }
   ],
   "source": [
    "# Dot product not using numpy\n",
    "import array \n",
    "  \n",
    "# 8 bytes size int \n",
    "a = array.array('q') \n",
    "for i in range(100000): \n",
    "    a.append(i); \n",
    "  \n",
    "b = array.array('q') \n",
    "for i in range(100000, 200000): \n",
    "    b.append(i) \n",
    "  \n",
    "# classic dot product of vectors implementation\n",
    "dot = 0.0  \n",
    "for i in range(len(a)): \n",
    "    dot += a[i] * b[i]\n",
    "\n",
    "print(dot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.6 ms ± 532 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "dot = 0.0\n",
    "for i in range(len(a)): \n",
    "    dot += a[i] * b[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blas_armpl_info:\n",
      "  NOT AVAILABLE\n",
      "blas_mkl_info:\n",
      "  NOT AVAILABLE\n",
      "blis_info:\n",
      "  NOT AVAILABLE\n",
      "openblas_info:\n",
      "  NOT AVAILABLE\n",
      "accelerate_info:\n",
      "  NOT AVAILABLE\n",
      "atlas_3_10_blas_threads_info:\n",
      "  NOT AVAILABLE\n",
      "atlas_3_10_blas_info:\n",
      "  NOT AVAILABLE\n",
      "atlas_blas_threads_info:\n",
      "  NOT AVAILABLE\n",
      "atlas_blas_info:\n",
      "  NOT AVAILABLE\n",
      "blas_info:\n",
      "    libraries = ['blas', 'blas']\n",
      "    library_dirs = ['/usr/lib/x86_64-linux-gnu']\n",
      "    include_dirs = ['/usr/local/include', '/usr/include']\n",
      "    language = c\n",
      "    define_macros = [('HAVE_CBLAS', None)]\n",
      "blas_opt_info:\n",
      "    define_macros = [('NO_ATLAS_INFO', 1), ('HAVE_CBLAS', None)]\n",
      "    libraries = ['blas', 'blas']\n",
      "    library_dirs = ['/usr/lib/x86_64-linux-gnu']\n",
      "    include_dirs = ['/usr/local/include', '/usr/include']\n",
      "    language = c\n",
      "lapack_armpl_info:\n",
      "  NOT AVAILABLE\n",
      "lapack_mkl_info:\n",
      "  NOT AVAILABLE\n",
      "openblas_lapack_info:\n",
      "  NOT AVAILABLE\n",
      "openblas_clapack_info:\n",
      "  NOT AVAILABLE\n",
      "flame_info:\n",
      "  NOT AVAILABLE\n",
      "atlas_3_10_threads_info:\n",
      "  NOT AVAILABLE\n",
      "atlas_3_10_info:\n",
      "  NOT AVAILABLE\n",
      "atlas_threads_info:\n",
      "  NOT AVAILABLE\n",
      "atlas_info:\n",
      "  NOT AVAILABLE\n",
      "lapack_info:\n",
      "    libraries = ['lapack', 'lapack']\n",
      "    library_dirs = ['/usr/lib/x86_64-linux-gnu']\n",
      "    language = f77\n",
      "lapack_opt_info:\n",
      "    libraries = ['lapack', 'lapack', 'blas', 'blas']\n",
      "    library_dirs = ['/usr/lib/x86_64-linux-gnu']\n",
      "    language = c\n",
      "    define_macros = [('NO_ATLAS_INFO', 1), ('HAVE_CBLAS', None)]\n",
      "    include_dirs = ['/usr/local/include', '/usr/include']\n",
      "Supported SIMD extensions in this NumPy install:\n",
      "    baseline = SSE,SSE2,SSE3\n",
      "    found = SSSE3,SSE41,POPCNT,SSE42,AVX,F16C,FMA3,AVX2\n",
      "    not found = AVX512F,AVX512CD,AVX512_SKX,AVX512_CLX,AVX512_CNL,AVX512_ICL\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# list compiling options of numpy to see which SIMD extension are supported\n",
    "np.show_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "833233335000.0\n"
     ]
    }
   ],
   "source": [
    "## using numpy arrays\n",
    "\n",
    "a = np.arange(0,10000)\n",
    "b = np.arange(10000,20000) \n",
    "\n",
    "dot = 0.0 \n",
    "for i in range(len(a)): \n",
    "      dot += a[i] * b[i] \n",
    "\n",
    "print(dot) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.81 ms ± 396 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "dot = 0.0 \n",
    "for i in range(len(a)): \n",
    "      dot += a[i] * b[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "833233335000\n"
     ]
    }
   ],
   "source": [
    "## Vectorize function\n",
    "dot = 0.0\n",
    "def mydot(a, b):\n",
    "    return a * b\n",
    "myvecdot = np.vectorize(mydot)\n",
    "print(np.sum(myvecdot(a,b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15 ms ± 82.8 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.sum(myvecdot(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUT: \n",
    "The vectorize function is provided primarily for convenience, not for performance. The implementation is essentially a for loop.\n",
    "\n",
    "See: https://numpy.org/doc/stable/reference/generated/numpy.vectorize.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "833233335000\n"
     ]
    }
   ],
   "source": [
    "## just using numpy's smart sum function\n",
    "\n",
    "print(np.sum(a*b, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.91 µs ± 352 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.sum(a*b, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "833233335000\n"
     ]
    }
   ],
   "source": [
    "## numpy dot function which is vectorized\n",
    "dot = np.dot(a, b)  \n",
    "\n",
    "print(dot) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.61 µs ± 371 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "dot = np.dot(a, b)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "833233335000\n"
     ]
    }
   ],
   "source": [
    "## numpy inner\n",
    "print(np.inner( a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.81 µs ± 480 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.inner(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "833233335000\n"
     ]
    }
   ],
   "source": [
    "## numpy einsum\n",
    "print(np.einsum('i,i', a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.75 µs ± 595 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.einsum('i,i', a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCIPY\n",
    "\n",
    "Example ivp:\n",
    "\n",
    "> vectorized: bool, optional\n",
    "\n",
    ">Whether fun can be called in a vectorized fashion. Default is False.\n",
    "If vectorized is False, fun will always be called with y of shape (n,), where n = len(y0).\n",
    "If vectorized is True, fun may be called with y of shape (n, k), where k is an integer. In this case, fun must behave such that fun(t, y)[:, i] == fun(t, y[:, i]) (i.e. each column of the returned array is the time derivative of the state corresponding with a column of y).\n",
    "Setting vectorized=True allows for faster finite difference approximation of the Jacobian by methods ‘Radau’ and ‘BDF’, but will result in slower execution for other methods and for ‘Radau’ and ‘BDF’ in some circumstances (e.g. small len(y0))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
